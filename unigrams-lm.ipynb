{
 "metadata": {
  "name": "unigrams-lm"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Unigrams Language Models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import codecs\n",
      "import math\n",
      "from __future__ import division\n",
      "from nltk.tokenize import word_tokenize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entrenamos el sistema con parte del corpus EFE94."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inputfile = \"/home/victor/tmp/efe/efetest.txt\"\n",
      "counts = {}\n",
      "total_counts = 0\n",
      "\n",
      "for line in codecs.open(inputfile, \"r\", \"utf-8\").readlines()[:1000]:\n",
      "    words = word_tokenize(line)\n",
      "    words.append(\"</s>\")\n",
      "    for word in words:\n",
      "        total_counts += 1\n",
      "        if counts.has_key(word):\n",
      "            counts[word] += 1\n",
      "        else:\n",
      "            counts[word] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Guardo el modelo en un fichero."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_model = codecs.open(\"/home/victor/tmp/efe/efe.freq.txt\", \"w\", \"utf-8\")\n",
      "\n",
      "for word, count in counts.items():\n",
      "    probability = counts[word]/total_counts\n",
      "    output_model.write(u\"%s %s\\n\" % (word, probability))\n",
      "\n",
      "output_model.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Y ahora probamos el modelo."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cargamos las probabilidades\n",
      "model = \"/home/victor/tmp/efe/efe.freq.txt\"\n",
      "probs = {}\n",
      "\n",
      "for line in codecs.open(model, \"r\", \"utf-8\").readlines():\n",
      "    w, p = line.split()\n",
      "    probs[w] = float(p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_model(model, test):\n",
      "    \"\"\"Test the model with a test input text.\"\"\"\n",
      "    lambda1 = 0.95\n",
      "    lambdaunk = 1 - lambda1\n",
      "    V = 1000000\n",
      "    W = 0\n",
      "    H = 0\n",
      "    unk = 0\n",
      "    for line in test.split(\"\\n\"):\n",
      "        words = word_tokenize(line)\n",
      "        words.append(\"</s>\")\n",
      "        for word in words:\n",
      "            W += 1\n",
      "            P = lambdaunk / V\n",
      "            if probs.has_key(word):\n",
      "                P += lambda1 * probs[word]\n",
      "            else:\n",
      "                unk += 1\n",
      "                H -= math.log(P, 2)\n",
      "            \n",
      "    print \"entropy:\", H/W \n",
      "    print \"coverage:\", (W-unk)/W, \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = \"\"\"Este ni\u00f1o ha nacido en Madrid.\n",
      "El presidente de Estados Unidos se llama Barack Obama.\"\"\"\n",
      "\n",
      "s2 = \"\"\"Il ragazzo \u00e8 nato in Sicilia.\"\"\"\n",
      "\n",
      "s3 = \"\"\"My neiborhood is located near the river.\n",
      "And I was born right there.\"\"\"\n",
      "\n",
      "s4 = \"\"\"El presidente de Guinea Ecuatorial, Teodoro\n",
      " Obiang Nguema, sugiri\u00f3 hoy, viernes, que su Gobierno podr\u00eda rechazar\n",
      " la ayuda internacional que recibe si \u00e9sta se condiciona a que en el\n",
      " pa\u00eds haya \"convulsiones pol\u00edticas\".\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_model(model, s1)\n",
      "test_model(model, s2)\n",
      "test_model(model, s3)\n",
      "test_model(model, s4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "entropy: 6.61458999933\n",
        "coverage: 0.727272727273 \n",
        "\n",
        "entropy: 13.4741648135\n",
        "coverage: 0.444444444444 \n",
        "\n",
        "entropy: 18.5467915667\n",
        "coverage: 0.235294117647 \n",
        "\n",
        "entropy: 4.25499941477\n",
        "coverage: 0.824561403509 \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}